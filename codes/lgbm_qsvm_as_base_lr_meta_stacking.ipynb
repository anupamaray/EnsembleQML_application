{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7TI0jzFo5fV_"
      },
      "source": [
        "# **Stacking with QSVM and LGBM as base classifiers and Logistic regressor(LR) as meta classifier**\n",
        "In this tutorial, we will see the classical stacking of QSVM,LGBM and LR algorithms, with QSVM, LGBM as base classifiers and LR as meta classifier. The stacking algorithm works as below\\\n",
        "1) The base classifiers are trained with training data\\\n",
        "2) The trained base classifiers are used to test both training data and testing data\\\n",
        "3) The output labels from base classifiers on training and testing data are appended as features to original training and testing data\\\n",
        "4) Now we train the meta classifier with appended training data and test it on appended testing data to get final prediction values\n",
        "\n"
      ],
      "id": "7TI0jzFo5fV_"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wwgHoJdKZBuf"
      },
      "source": [
        "Below is detailed explanation and implementation of each of above steps\n"
      ],
      "id": "wwgHoJdKZBuf"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CDRv2RL3fF42"
      },
      "source": [
        "We first need to install qiskit and qiskit_machine_learning modules if not already installed. We start by importing all necessary libraries from qiskit,  qiskit\\_machine\\_learning and some related modules as shown in below cells."
      ],
      "id": "CDRv2RL3fF42"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ba5f1a2c",
      "metadata": {
        "id": "ba5f1a2c"
      },
      "outputs": [],
      "source": [
        "from qiskit import BasicAer\n",
        "from qiskit.utils import QuantumInstance, algorithm_globals\n",
        "from qiskit.algorithms.optimizers import COBYLA\n",
        "from qiskit.circuit.library import TwoLocal\n",
        "from qiskit_machine_learning.algorithms import VQC, QSVC\n",
        "from qiskit_machine_learning.circuit.library import RawFeatureVector\n",
        "from qiskit.circuit.library import RealAmplitudes, ZZFeatureMap, ZFeatureMap, NLocal\n",
        "from qiskit import QuantumCircuit\n",
        "from qiskit.circuit import Parameter\n",
        "from qiskit_machine_learning.kernels import QuantumKernel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5a0ab1a5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5a0ab1a5",
        "outputId": "584a4e9f-4deb-47ae-efb2-abd3d67f2c0a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['/content', '/env/python', '/usr/lib/python37.zip', '/usr/lib/python3.7', '/usr/lib/python3.7/lib-dynload', '', '/usr/local/lib/python3.7/dist-packages', '/usr/lib/python3/dist-packages', '/usr/local/lib/python3.7/dist-packages/IPython/extensions', '/root/.ipython']\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "print(sys.path)\n",
        "sys.path.append(\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c5f149ce",
      "metadata": {
        "id": "c5f149ce"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn import svm, metrics\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from time import time\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import lightgbm as lgb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lTQ4H2QEnxqY"
      },
      "source": [
        "###Data set\n",
        "We use ethereum networks data to perform stacking. We consider 7 features for data set\\\n",
        "1) Degree - In degree, Out degree, Total degree\\\n",
        "2) Strength - In strength, Out strength, Total strength\\\n",
        "3) Number of neighbours\n",
        "\n",
        "The files 'train_data.npy' and 'train_labels.npy' have 960 training data points and corresponding labels respectively, first 160 training data points are of phishing nodes and next 800 are of non-phishing nodes. The files 'test_data.npy' and 'test_labels.npy' have 11000 testing data points and corresponding labels respectively, first 1000 testing data points are of phishing nodes and next 10000 are of non-phishing nodes.\n",
        "\n",
        "\n",
        "let us choose 320 training data points to perform stacking, 160 phishing and 160 non-phishing. Even though the real life data is highly imbalanced, we choose equal number of phishing and non-phishing nodes for training our classifiers and then test on imbalanced testing data. With different experiments on this data set, taking balanced training data proved more effective in giving good results"
      ],
      "id": "lTQ4H2QEnxqY"
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = np.load('train_data.npy')\n",
        "train_labels = np.load('train_labels.npy')\n",
        "test_data = np.load('test_data.npy')\n",
        "test_labels = np.load('test_labels.npy')\n",
        "train_data = train_data[:320]\n",
        "train_labels = train_labels[:320]"
      ],
      "metadata": {
        "id": "-krDqLyFjS_b"
      },
      "id": "-krDqLyFjS_b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6kohburWkZdG"
      },
      "source": [
        "# Classical SVM training and testing\n",
        "We perform classical support vector machine classification to compare our final results"
      ],
      "id": "6kohburWkZdG"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a3e4eba1",
      "metadata": {
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a3e4eba1",
        "outputId": "bcacf766-2d68-408b-e8c5-d680656512a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*** Training a classical SVM classifier with rbf Kernel ***\n",
            "training time for classical SVM :  0.009143829345703125\n",
            "[[9676  324]\n",
            " [ 559  441]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.97      0.96     10000\n",
            "           1       0.58      0.44      0.50      1000\n",
            "\n",
            "    accuracy                           0.92     11000\n",
            "   macro avg       0.76      0.70      0.73     11000\n",
            "weighted avg       0.91      0.92      0.91     11000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#training classical SVM with rbf kernel\n",
        "\n",
        "print(\"*** Training a classical SVM classifier with rbf Kernel ***\")\n",
        "\n",
        "#converting two dimensional labels to 1D\n",
        "train_labels_svm = train_labels[:,0]\n",
        "test_labels_svm = test_labels[:,0]\n",
        "\n",
        "clf = svm.SVC(kernel='rbf')\n",
        "start_time = time()\n",
        "clf.fit(train_data, train_labels_svm)\n",
        "end_time = time()\n",
        "duration = end_time - start_time\n",
        "print(\"training time for classical SVM : \", duration)\n",
        "y_pred=clf.predict(test_data)\n",
        "print(confusion_matrix(test_labels_svm, y_pred))\n",
        "print(classification_report(test_labels_svm, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GrFgO9MIki6L"
      },
      "source": [
        "# **Stacking**\n",
        "###Initializing the classifiers\n",
        "Initialize the two base classifiers QSVM and LGBM. ZZ feature map is used to calculate kernel matrix for QSVM classifier. \n",
        "It can be calculated using below equation\\\n",
        "$K(\\vec{x_i},\\vec{x_j}) =K_{ij}= \\vert\\langle\\phi^\\dagger(\\vec{x_j})\\vert\\phi(\\vec{x_i})\\rangle\\vert^2$, where $x_i,x_j\\in X$(training data set) and $\\phi$ represents feature map \n",
        "\n",
        "Statevector simulator is used to simulate the results of quantum computer, it can be replaced with backend for harware results\n",
        "\n",
        "In this tutorial we are considering two base classifiers, the second one is classical ML algorithm LGBM\n",
        "\n",
        "Over these two base classifiers we use Logistic regression as meta classifier"
      ],
      "id": "GrFgO9MIki6L"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "79a6dd54",
      "metadata": {
        "id": "79a6dd54"
      },
      "outputs": [],
      "source": [
        "seed = 1376\n",
        "\n",
        "#feature dimensions\n",
        "feature_dim = train_data.shape[1]\n",
        "\n",
        "#feature map to calculate kernel of QSVM\n",
        "feature_map = ZZFeatureMap(feature_dim)\n",
        "\n",
        "#initialize LGBM classifier\n",
        "clf = lgb.LGBMClassifier()\n",
        "\n",
        "#initialize kernel of QSVM\n",
        "kernel = QuantumKernel(feature_map=feature_map,\n",
        "                             quantum_instance=QuantumInstance(BasicAer.get_backend('statevector_simulator'),\n",
        "                                            shots=1,\n",
        "                                            seed_simulator=seed,\n",
        "                                                              seed_transpiler=seed))\n",
        "\n",
        "#initialize QSVM\n",
        "qsvc = QSVC(quantum_kernel=kernel)\n",
        "lr = LogisticRegression()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u_MTPctWV8f4"
      },
      "source": [
        "###Training the base classifiers\n",
        "In the following cells we train the base classifiers QSVM and LGBM using 320 training data points, then we predict the labels of both training data and testing data using the trained classifiers, the labels we obtained are added as features to initial training and testing data sets, thus our final training data and testing data with appended features consists of total 9 features(one label is added from each classifier)"
      ],
      "id": "u_MTPctWV8f4"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2e8cc882",
      "metadata": {
        "id": "2e8cc882"
      },
      "outputs": [],
      "source": [
        "#train base classifiers and append features to data\n",
        "\n",
        "def level_0():\n",
        "    \n",
        "    #Use QSVM and LGBM on train data, append the predicted labels on train data to train data features\n",
        "    clf.fit(train_data,train_labels_svm)\n",
        "    b = clf.predict(train_data)\n",
        "    label_2 = np.reshape(b,(len(b),1))\n",
        "    qsvc.fit(train_data, train_labels_svm)\n",
        "    c = qsvc.predict(train_data)\n",
        "    label_3 = np.reshape(c,(len(c),1))\n",
        "    t1 = np.append(train_data,label_2,1)\n",
        "    train_added = np.append(t1,label_3,1)\n",
        "    \n",
        "    #append the predicted labels on test data to test data features\n",
        "    e = clf.predict(test_data)\n",
        "    label_5 = np.reshape(e,(len(e),1))\n",
        "    f = qsvc.predict(test_data)\n",
        "    label_6 = np.reshape(f,(len(f),1))\n",
        "    t3 = np.append(test_data,label_5,1)\n",
        "    test_added = np.append(t3,label_6,1)\n",
        "    \n",
        "    return train_added,test_added"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f17498af",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f17498af",
        "outputId": "4ffac204-909d-4778-fcb5-2092dbec8562"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training time :  193.53476977348328\n"
          ]
        }
      ],
      "source": [
        "# initialize logistic regressor and get appended train and test data\n",
        "\n",
        "start_time = time()\n",
        "train_added, test_added = level_0()\n",
        "end_time = time()\n",
        "duration = end_time - start_time\n",
        "print(\"training time : \", duration)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ms-ozvtOW5Ir"
      },
      "source": [
        "###Training the meta classifier\n",
        "The LR classifier is now trained with training data of 320 data points with 9 features (7 features + one feature from prediction label of that particular training data point using QSVM + one feature from prediction label of that particular training data point using LGBM)"
      ],
      "id": "ms-ozvtOW5Ir"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0112289c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0112289c",
        "outputId": "3fd521c1-f354-4d24-9863-040ec09b7ff7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training_data (320, 7)\n",
            "training time :  0.03599047660827637\n"
          ]
        }
      ],
      "source": [
        "#train logistic regressor using appended train data\n",
        "\n",
        "start_time = time()\n",
        "print(\"training_data\", train_data.shape)\n",
        "lr.fit(train_added, train_labels_svm)\n",
        "end_time = time()\n",
        "duration = end_time - start_time\n",
        "print(\"training time : \", duration)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AY4CBgVPXslx"
      },
      "source": [
        "###Get final prediction\n",
        "We test the appended data set with 9 features (7 features + one feature from prediction label of that particular test data point using QSVM + one feature from prediction label of that particular test data point using LGBM) using the trained meta classifier (LR) and get our final prediction results"
      ],
      "id": "AY4CBgVPXslx"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ffbb5b8d",
      "metadata": {
        "id": "ffbb5b8d",
        "outputId": "02c04f22-4f73-47b4-e146-941e1f3b6af9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "testing time :  0.001850128173828125\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.91      0.95     10000\n",
            "           1       0.53      0.97      0.68      1000\n",
            "\n",
            "    accuracy                           0.92     11000\n",
            "   macro avg       0.76      0.94      0.82     11000\n",
            "weighted avg       0.95      0.92      0.93     11000\n",
            "\n",
            "[[9130  870]\n",
            " [  33  967]]\n"
          ]
        }
      ],
      "source": [
        "# predict on appended test data\n",
        "\n",
        "start_time1 = time()\n",
        "y_pred_1 = lr.predict(test_added)\n",
        "end_time1 = time()\n",
        "duration1 = end_time1 - start_time1\n",
        "print(\"testing time : \", duration1)\n",
        "print(classification_report(test_labels_svm,y_pred_1))\n",
        "print(confusion_matrix(test_labels_svm,y_pred_1))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.13"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}